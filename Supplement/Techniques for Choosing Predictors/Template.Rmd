---
title: "Supplement for Lecture 17: Techniques for Choosing Predictors"
output:
  pdf_document: default
---

```{r setup, include=FALSE}
#This code chunk is for modifying the global options and for loading required R packages
knitr::opts_chunk$set(echo = TRUE)
options(scipen=999) #Prevents the use of scientific notation
library(rmarkdown)
library(tinytex)
library(knitr)
library(readr)
library(mosaic) 
library(Lock5Data) #Install this Package
library(leaps)  #Install this Package
library(corrplot) #Install this Package
library(PerformanceAnalytics) #Install this Package
library(car) #Install this Package

source("https://raw.githubusercontent.com/JA-McLean/STOR455/master/scripts/ShowSubsets.R") 
```

# Load Data 

```{r, message=FALSE}
data("BodyFat") # Load Data

bf = BodyFat

head(bf)
```


# Check for Multicollinearity 

```{r, warning=FALSE, eval=FALSE}
# Correlation Matrix from Base R


# Tile Plot of Correlation Matrix (Correlogram) from corrplot package


#Scatterplots of Bodyfat Variable with Each Other Predictor


# Cool Visual from PerformanceAnalytics package

```
# Variance Inflation Factor

```{r, eval=FALSE}
mod.full = lm(COMPLETE,data=bf)
summary(mod.full)
plot(mod.full)
vif(mod.full) # From car package
```

```{r, eval=FALSE}
mod.noWeight = lm(COMPLETE,data=bf)
vif(mod.noWeight)

mod.noWeightChest = lm(COMPLETE,data=bf)
vif(mod.noWeightChest)
```

# Fit All Subsets

The `regsubsets()` function fits all subset models up to a maximum number of variables. Notice the `nvmax` argument. The asterisk indicates which variables are included in the best model for each possible choice for $k$.

```{r, eval=FALSE}
all =  #From leaps package
summary(all)

all2 =  #From leaps package
summary(all2)
```

Now we identify the "best" model based off the criteria R-Squared, adjusted R-Squared, and Mallow's Cp. We can use the `ShowSubsets()` function created by Dr. McLean.

```{r, eval=FALSE}


# Best Model According to R-Squared
out2[COMPLETE,]

# Best Model According to Adjusted R-Squared
out2[COMPLETE,]

# Best Model According to Mallows Cp
out2[COMPLETE,]
```

We can also tell the function using `nbest` the number of top models for each choice of $k$ that we want to see in the output. We can also calculate the BIC for each of the models and identify the best model according to BIC.

```{r, eval=FALSE}
all3 = COMPLETE
out3 = ShowSubsets(all3) 
out3

#Get BIC for each of the models
summ.all3 = COMPLETE
summ.all3$bic

#Find Best Model According to BIC
out3[which.min(summ.all3$bic),]

#Calculated adjusted R-squared by hand
1-(1-0.7471)*((100-1)/(100-3-1)) #Notice these equals the adjusted R-Squared in the BIC Model
```

Now we fit our "best" models according to adjusted R-squared/Mallow's Cp and BIC.

```{r, eval=FALSE}
mod.rsqmallow = lm(Bodyfat ~ Age + Weight + Abdomen + Wrist, data=bf)
plot(mod.rsqmallow)
vif(mod.rsqmallow)

mod.bic = lm(Bodyfat ~ Weight + Abdomen + Wrist,data=bf)
plot(mod.bic)
vif(mod.bic)
```


# Backwards, Forwards, and Stepwise Algorithms

Built-in `step()` function doesn't use p-values to determine what variables to remove or keep. It uses the AIC measurement which is similar to BIC. Let's first look at backward's elimination.

```{r, eval=FALSE}



summary(back.out)
vif(back.out)
```

Now let's look at forward selection. In this case, we need to start by initiating the empty model and telling the `step()` function to consider all models up to possibly the full model.

```{r, eval=FALSE}



summary(forward.out)
vif(forward.out)
```

Now, we specify the `direction="both"` to conduct stepwise regression where variables can be both added and removed.

```{r, eval=FALSE}



summary(step.out)
vif(step.out)
```

# All Models Summarized

```{r, eval=FALSE}
mod.full
mod.noWeight
mod.noWeightChest
mod.rsqmallow
mod.bic
back.out
forward.out
step.out
```

















